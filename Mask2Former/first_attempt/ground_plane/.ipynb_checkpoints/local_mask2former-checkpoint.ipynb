{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QHnVupBBn9eR"
   },
   "source": [
    "# \"[Mask2Former](https://arxiv.org/abs/2112.01527)\" Tutorial\n",
    "\n",
    "<img src=\"https://bowenc0221.github.io/images/maskformerv2_teaser.png\" width=\"500\"/>\n",
    "\n",
    "Welcome to the [Mask2Former](https://github.com/facebookresearch/Mask2Former) in detectron2! In this tutorial, we will go through some basics usage of Mask2Former, including the following:\n",
    "* Run inference on images or videos, with an existing Mask2Former model\n",
    "\n",
    "You can make a copy of this tutorial or use \"File -> Open in playground mode\" to play with it yourself. **DO NOT** request access to this tutorial.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vM54r6jlKTII"
   },
   "source": [
    "# Install detectron2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Znw6-BZHOvqt",
    "outputId": "66c62056-b2dc-4604-ec3d-3a66704ab868"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2020 NVIDIA Corporation\n",
      "Built on Tue_Sep_15_19:10:02_PDT_2020\n",
      "Cuda compilation tools, release 11.1, V11.1.74\n",
      "Build cuda_11.1.TC455_06.29069683_0\n",
      "torch:  1.10 ; cuda:  cu111\n",
      "detectron2: 0.6\n"
     ]
    }
   ],
   "source": [
    "import torch, detectron2\n",
    "!nvcc --version\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "print(\"detectron2:\", detectron2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OOr76FECUCXP",
    "outputId": "e4a3625c-4436-4189-90c9-d3e6e3c8d7c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torchvision:  0.11\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "TORCHVISION_VERSION = \".\".join(torchvision.__version__.split(\".\")[:2])\n",
    "print(\"torchvision: \", TORCHVISION_VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tu8jWrMs6fOm"
   },
   "source": [
    "# Install Mask2Former"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ipanigra/Documents'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ipanigra/Documents/Mask2Former/mask2former/modeling/pixel_decoder/ops\n",
      "running build\n",
      "running build_py\n",
      "running build_ext\n",
      "/home/ipanigra/Documents/riss2022/lib/python3.7/site-packages/torch/utils/cpp_extension.py:381: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
      "  warnings.warn(msg.format('we could not find ninja.'))\n",
      "running install\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "writing MultiScaleDeformableAttention.egg-info/PKG-INFO\n",
      "writing dependency_links to MultiScaleDeformableAttention.egg-info/dependency_links.txt\n",
      "writing top-level names to MultiScaleDeformableAttention.egg-info/top_level.txt\n",
      "reading manifest file 'MultiScaleDeformableAttention.egg-info/SOURCES.txt'\n",
      "writing manifest file 'MultiScaleDeformableAttention.egg-info/SOURCES.txt'\n",
      "installing library code to build/bdist.linux-x86_64/egg\n",
      "running install_lib\n",
      "creating build/bdist.linux-x86_64/egg\n",
      "creating build/bdist.linux-x86_64/egg/modules\n",
      "copying build/lib.linux-x86_64-3.7/modules/__init__.py -> build/bdist.linux-x86_64/egg/modules\n",
      "copying build/lib.linux-x86_64-3.7/modules/ms_deform_attn.py -> build/bdist.linux-x86_64/egg/modules\n",
      "copying build/lib.linux-x86_64-3.7/MultiScaleDeformableAttention.cpython-37m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
      "creating build/bdist.linux-x86_64/egg/functions\n",
      "copying build/lib.linux-x86_64-3.7/functions/__init__.py -> build/bdist.linux-x86_64/egg/functions\n",
      "copying build/lib.linux-x86_64-3.7/functions/ms_deform_attn_func.py -> build/bdist.linux-x86_64/egg/functions\n",
      "byte-compiling build/bdist.linux-x86_64/egg/modules/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/modules/ms_deform_attn.py to ms_deform_attn.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/functions/__init__.py to __init__.cpython-37.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/functions/ms_deform_attn_func.py to ms_deform_attn_func.cpython-37.pyc\n",
      "creating stub loader for MultiScaleDeformableAttention.cpython-37m-x86_64-linux-gnu.so\n",
      "byte-compiling build/bdist.linux-x86_64/egg/MultiScaleDeformableAttention.py to MultiScaleDeformableAttention.cpython-37.pyc\n",
      "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying MultiScaleDeformableAttention.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying MultiScaleDeformableAttention.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying MultiScaleDeformableAttention.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying MultiScaleDeformableAttention.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "__pycache__.MultiScaleDeformableAttention.cpython-37: module references __file__\n",
      "creating 'dist/MultiScaleDeformableAttention-1.0-py3.7-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
      "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
      "Processing MultiScaleDeformableAttention-1.0-py3.7-linux-x86_64.egg\n",
      "removing '/home/ipanigra/Documents/riss2022/lib/python3.7/site-packages/MultiScaleDeformableAttention-1.0-py3.7-linux-x86_64.egg' (and everything under it)\n",
      "creating /home/ipanigra/Documents/riss2022/lib/python3.7/site-packages/MultiScaleDeformableAttention-1.0-py3.7-linux-x86_64.egg\n",
      "Extracting MultiScaleDeformableAttention-1.0-py3.7-linux-x86_64.egg to /home/ipanigra/Documents/riss2022/lib/python3.7/site-packages\n",
      "MultiScaleDeformableAttention 1.0 is already the active version in easy-install.pth\n",
      "\n",
      "Installed /home/ipanigra/Documents/riss2022/lib/python3.7/site-packages/MultiScaleDeformableAttention-1.0-py3.7-linux-x86_64.egg\n",
      "Processing dependencies for MultiScaleDeformableAttention==1.0\n",
      "Finished processing dependencies for MultiScaleDeformableAttention==1.0\n",
      "/home/ipanigra/Documents/Mask2Former\n"
     ]
    }
   ],
   "source": [
    "# for local use\n",
    "%cd Mask2Former/mask2former/modeling/pixel_decoder/ops\n",
    "!python setup.py build install\n",
    "%cd ../../../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZyAvNCJMmvFF",
    "outputId": "173b8131-f8fe-4c40-95f8-1d7994b2d8ac"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mask2former'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26782/3198350033.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# import Mask2Former project\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmask2former\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0madd_maskformer2_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mask2former'"
     ]
    }
   ],
   "source": [
    "# You may need to restart your runtime prior to this, to let your installation take effect\n",
    "\n",
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "setup_logger(name=\"mask2former\")\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "# from google.colab.patches import cv2_imshow\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.projects.deeplab import add_deeplab_config\n",
    "coco_metadata = MetadataCatalog.get(\"mapillary_vistas_panoptic_val\")\n",
    "\n",
    "# import Mask2Former project\n",
    "from mask2former import add_maskformer2_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vk4gID50K03a"
   },
   "source": [
    "# Run a pre-trained Mask2Former model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JgKyUL4pngvE"
   },
   "source": [
    "We first download an image from the COCO dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_name = 'Image'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 668
    },
    "id": "dq9GY37ml1kr",
    "outputId": "53155fdd-d41f-4616-d2e1-d04d956d8e5b"
   },
   "outputs": [],
   "source": [
    "# !wget http://images.cocodataset.org/val2017/000000005477.jpg -q -O input.jpg\n",
    "im = cv2.imread(\"./input.jpg\")\n",
    "cv2.imshow(window_name,im)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r7sw7uz9Vyo-"
   },
   "source": [
    "Then, we create a detectron2 config and a detectron2 `DefaultPredictor` to run inference on this image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HUjkwRsOn1O0",
    "outputId": "587d3e25-fe7d-44fa-9040-e309d55524f8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading config configs/mapillary-vistas/panoptic-segmentation/swin/../Base-MapillaryVistas-PanopticSegmentation.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.\n",
      "/home/ipanigra/Documents/riss2022/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[07/21 14:51:50 mask2former.modeling.transformer_decoder.mask2former_transformer_decoder]: \u001b[0mWeight format of MultiScaleMaskedTransformerDecoder have changed! Please upgrade your models. Applying automatic conversion now ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ipanigra/Documents/Mask2Former/mask2former/modeling/transformer_decoder/position_encoding.py:41: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats)\n",
      "/home/ipanigra/Documents/Mask2Former/mask2former/maskformer_model.py:355: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  topk_indices = topk_indices // self.sem_seg_head.num_classes\n"
     ]
    }
   ],
   "source": [
    "cfg = get_cfg()\n",
    "add_deeplab_config(cfg)\n",
    "add_maskformer2_config(cfg)\n",
    "# coco\n",
    "# cfg.merge_from_file(\"configs/coco/panoptic-segmentation/swin/maskformer2_swin_large_IN21k_384_bs16_100ep.yaml\")\n",
    "# cfg.MODEL.WEIGHTS = 'https://dl.fbaipublicfiles.com/maskformer/mask2former/coco/panoptic/maskformer2_swin_large_IN21k_384_bs16_100ep/model_final_f07440.pkl'\n",
    "# mapillary vistas\n",
    "cfg.merge_from_file(\"configs/mapillary-vistas/panoptic-segmentation/swin/maskformer2_swin_large_IN21k_384_bs16_300k.yaml\")\n",
    "cfg.MODEL.WEIGHTS = 'https://dl.fbaipublicfiles.com/maskformer/mask2former/mapillary_vistas/panoptic/maskformer2_swin_large_IN21k_384_bs16_300k/model_final_132c71.pkl'\n",
    "# cityscapes\n",
    "# cfg.merge_from_file(\"configs/cityscapes/semantic-segmentation/swin/maskformer2_swin_small_bs16_90k.yaml\")\n",
    "# cfg.MODEL.WEIGHTS = 'https://dl.fbaipublicfiles.com/maskformer/mask2former/cityscapes/semantic/maskformer2_swin_tiny_bs16_90k/model_final_2d58d4.pkl'\n",
    "cfg.MODEL.MASK_FORMER.TEST.SEMANTIC_ON = True\n",
    "cfg.MODEL.MASK_FORMER.TEST.INSTANCE_ON = True\n",
    "cfg.MODEL.MASK_FORMER.TEST.PANOPTIC_ON = True\n",
    "predictor = DefaultPredictor(cfg)\n",
    "outputs = predictor(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False]], device='cuda:0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[\"sem_seg\"].argmax(0)==13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "720"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stuff_classes = MetadataCatalog.get(cfg.DATASETS.TRAIN[0]).stuff_classes\n",
    "classes = (np.arange(len(stuff_classes))==13)\n",
    "classes\n",
    "len(outputs[\"sem_seg\"][classes][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8IRGo8d0qkgR",
    "outputId": "69c6dd47-efbf-4eee-a068-66ad808bfa2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Panoptic segmentation (top), instance segmentation (middle), semantic segmentation (bottom)\n"
     ]
    }
   ],
   "source": [
    "# Show panoptic/instance/semantic predictions: \n",
    "# v = Visualizer(im[:, :, ::-1], coco_metadata, scale=1.2, instance_mode=ColorMode.IMAGE_BW)\n",
    "# panoptic_result = v.draw_panoptic_seg(outputs[\"panoptic_seg\"][0].to(\"cpu\"), outputs[\"panoptic_seg\"][1]).get_image()\n",
    "# v = Visualizer(im[:, :, ::-1], coco_metadata, scale=1.2, instance_mode=ColorMode.IMAGE_BW)\n",
    "# instance_result = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\")).get_image()\n",
    "v = Visualizer(im[:, :, ::-1], coco_metadata, scale=1.2, instance_mode=ColorMode.IMAGE_BW)\n",
    "semantic_result = v.draw_sem_seg((outputs[\"sem_seg\"].argmax(0)==13).to(\"cpu\")*13).get_image()\n",
    "print(\"Panoptic segmentation (top), instance segmentation (middle), semantic segmentation (bottom)\")\n",
    "# cv2.imshow(window_name, np.concatenate((panoptic_result, instance_result, semantic_result), axis=0)[:, :, ::-1])\n",
    "cv2.imshow(window_name, semantic_result[:, :, ::-1])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Mask2Former Tutorial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
